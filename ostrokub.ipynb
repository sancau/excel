{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "import re\n",
    "import os, sys\n",
    "import openpyxl\n",
    "\n",
    "\"\"\"\n",
    "DATA CONFIG\n",
    "\"\"\"\n",
    "INDEX = 0\n",
    "NAME = 1\n",
    "SIZE = 6\n",
    "AMOUNT = 11\n",
    "MATERIAL = 12\n",
    "UNITS = 17\n",
    "MATERIAL_AMOUNT = 19\n",
    "STANDART = 21\n",
    "COMMENT = 24\n",
    "\n",
    "PAYLOAD_DATA_INDEXES = [\n",
    "    INDEX, NAME, SIZE, \n",
    "    AMOUNT, MATERIAL, UNITS, \n",
    "    MATERIAL_AMOUNT, STANDART, \n",
    "    COMMENT\n",
    "]\n",
    "\n",
    "FISRT_LIST = 'Лист1'\n",
    "FISRT_LIST_FIRST_DATA_ROW = 22\n",
    "OTHER_LISTS_FIRST_DATA_ROW = 2\n",
    "\n",
    "REPEAT_SYMBOLS = ['——ıı——',]\n",
    "\n",
    "\"\"\"\n",
    "SCRIPT CONFIG\n",
    "\"\"\"\n",
    "DEFAULT_DIR_PATH = os.path.dirname(sys.argv[0])\n",
    "DEFUALT_RESULT_FILE_NAME = 'output.xls'\n",
    "DEFAULT_RESULT_FILE_PATH = \\\n",
    "    os.path.join(DEFAULT_DIR_PATH, DEFUALT_RESULT_FILE_NAME)\n",
    "\n",
    "\"\"\"\n",
    "LOGIC\n",
    "\"\"\"    \n",
    "def get_files(dir_path=DEFAULT_DIR_PATH):\n",
    "    \"\"\"\n",
    "    Returns list of excel file paths in\n",
    "    a given directory\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for path, subdirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            if file_extension in ['.xls', '.xlsx']:\n",
    "                file_path = os.path.join(path, file)\n",
    "                print(file_path)\n",
    "                result.append(file_path)   \n",
    "    return result\n",
    "\n",
    "def merge(rows):\n",
    "    \"\"\"\n",
    "    Parse a row of the table.\n",
    "    Add data to result dict.\n",
    "    \n",
    "    If this key exists in the dict process its params\n",
    "    and add the amount\n",
    "    Else - add new key in dict\n",
    "    \"\"\"\n",
    "    # clean data from openpyxl wrappers\n",
    "    plain_rows = []\n",
    "    for row in rows:\n",
    "        plain_row = [item.value for item in row]               \n",
    "        plain_rows.append(plain_row)\n",
    "    \n",
    "    #handle repeat sybmols\n",
    "    for row_index, plain_row in enumerate(plain_rows):\n",
    "        for value_index, value in enumerate(plain_row):\n",
    "            if value in REPEAT_SYMBOLS:\n",
    "                plain_row[value_index] = plain_rows[row_index - 1][value_index] \n",
    "    \n",
    "    filtered_rows = [\n",
    "        row for row in plain_rows if row[NAME] is not None and row[INDEX] is not None\n",
    "    ] \n",
    "    \n",
    "    print('Данные после импорта файлов и первичной фильтрации:')\n",
    "    print('Index | Name | Size | Amount | Material | Units | Material Amount | Standart | Comment')\n",
    "    print('___________________________________________________')\n",
    "    print(' ')\n",
    "    \n",
    "    for row in [[cell for cell_index, cell in enumerate(row) if cell_index in PAYLOAD_DATA_INDEXES] for row in filtered_rows]:\n",
    "        print(row)\n",
    "    \n",
    "    def remove_spaces(value):\n",
    "        \"\"\"\n",
    "        Returns given string with all the spaces removed.\n",
    "        \"\"\"\n",
    "        return re.sub('[\\s+]', '', str(value))\n",
    "    \n",
    "    def get_size(row):\n",
    "        \"\"\"\n",
    "        Returns main size criteria for a given row.\n",
    "        \"\"\"\n",
    "        return remove_spaces(str(row[SIZE])).split('×')[0]\n",
    "           \n",
    "    def get_match(row, output):\n",
    "        \"\"\"\n",
    "        Checks if given row has a match in output array.\n",
    "        \"\"\"\n",
    "        standart_match = [r for r in output if remove_spaces(r[STANDART]) == remove_spaces(row[STANDART])]\n",
    "        if not standart_match:\n",
    "            print('adding by \"STANDART\": ', row[STANDART])\n",
    "            output.append(row)\n",
    "            return None\n",
    "        else:\n",
    "            material_match = [r for r in standart_match if remove_spaces(r[MATERIAL]) == remove_spaces(row[MATERIAL])]\n",
    "            if not material_match:\n",
    "                print('adding by \"MATERIAL\": ', row[MATERIAL])\n",
    "                output.append(row)\n",
    "                return None\n",
    "            else:\n",
    "                size_match = [r for r in material_match if get_size(r) == get_size(row)]\n",
    "                if not size_match:\n",
    "                    print('adding by \"SIZE\": ', row[SIZE])\n",
    "                    output.append(row)\n",
    "                    return None\n",
    "                else:\n",
    "                    print('Found %s merge candidates!' % len(size_match))\n",
    "                    if len(size_match) > 1:\n",
    "                        raise Exception('MORE THEN 1 MERGE CANDIDATE WAS FOUND. PARSING ALGORYTHM IS INVALID!') \n",
    "                    print('for merge: %s' % row)\n",
    "                    print('host row: %s' % size_match[0])\n",
    "                    return size_match[0]\n",
    "                 \n",
    "    def merge_data(new, existed):\n",
    "        \"\"\"\n",
    "        Appends row data to an existed row if match was confirmed.\n",
    "        \n",
    "        Apply merge politics here to inject new in existed.\n",
    "        \"\"\"\n",
    "        print('Merging...')\n",
    "        print(new)\n",
    "        print(existed)\n",
    "        if existed[NAME] != new[NAME]:\n",
    "            print('Names are different')\n",
    "            existed[NAME] = ', '.join([existed[NAME], new[NAME]])\n",
    "            print('Name set to %s:' % existed[NAME])\n",
    "        print('Merging sizes / amounts...')\n",
    "        size_amount_existed = ', '.join([str(existed[SIZE]), str(existed[AMOUNT])])\n",
    "        size_amount_new = ', '.join([str(new[SIZE]), str(new[AMOUNT])])\n",
    "        existed[SIZE] = '; '.join([size_amount_existed, size_amount_new])\n",
    "        print('Merge result: ')\n",
    "        print(existed)\n",
    "        return existed\n",
    "  \n",
    "    output = []\n",
    "    print(' ')\n",
    "    print('Processing output...')\n",
    "    print(' ')\n",
    "    for row in filtered_rows:\n",
    "        match = get_match(row, output)\n",
    "        print(len(output))\n",
    "        if match:\n",
    "            output[output.index(match)] = merge_data(row, match)\n",
    "    \n",
    "    filtered_output = []\n",
    "    index = 1\n",
    "    for row in [[cell for cell_index, cell in enumerate(row) if cell_index in PAYLOAD_DATA_INDEXES] for row in output]:\n",
    "        row[0] = index\n",
    "        filtered_output.append(row)\n",
    "        index += 1\n",
    "    return filtered_output\n",
    "\n",
    "def build_results_file(results_dict, results_file_path=DEFAULT_RESULT_FILE_PATH):\n",
    "    \"\"\"\n",
    "    Build an excel file based on results dict and \n",
    "    a given path.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def process(dir_path=DEFAULT_DIR_PATH, result_file_path=DEFAULT_RESULT_FILE_PATH):\n",
    "    try:\n",
    "        files = get_files(dir_path)\n",
    "        rows_to_process = []\n",
    "        if files:\n",
    "            for file in files:\n",
    "                workbook = openpyxl.load_workbook(filename=file)   \n",
    "                for sheet in workbook:\n",
    "                    for row in sheet:\n",
    "                        # add rows by certain condition\n",
    "                        row_index = (lambda x: x[0].row)(row)\n",
    "                        if (sheet is not workbook[FISRT_LIST] \\\n",
    "                        and row_index >= OTHER_LISTS_FIRST_DATA_ROW) \\\n",
    "                            or row_index >= FISRT_LIST_FIRST_DATA_ROW:\n",
    "                            rows_to_process.append(row) \n",
    "                            \n",
    "            merged_rows = merge(rows_to_process)\n",
    "            \n",
    "            print('MERGE RESULT: ')\n",
    "            for row in merged_rows:\n",
    "                print(row)\n",
    "                \n",
    "            build_results_file(merged_rows) \n",
    "            print('Success')\n",
    "        else:\n",
    "            print('No files to process')\n",
    "    \n",
    "    except Exception as ex:\n",
    "        print('Error while processing')\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = 'C:/kub'\n",
    "process(dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
